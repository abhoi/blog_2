<!DOCTYPE html>
<html>
  <head>
    <title>Introduction to Conditional Random Fields – Amlaan Bhoi's Blog</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="Conditional Random Fields (CRFs) are a class of statistical modeling method often to used to model structured data. CRFs are widely used in machine learning problems. Some specific applications include:

" />
    <meta property="og:description" content="Conditional Random Fields (CRFs) are a class of statistical modeling method often to used to model structured data. CRFs are widely used in machine learning problems. Some specific applications include:

" />
    
    <meta name="author" content="Amlaan Bhoi" />

    
    <meta property="og:title" content="Introduction to Conditional Random Fields" />
    <meta property="twitter:title" content="Introduction to Conditional Random Fields" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Amlaan Bhoi Blog" href="/feed.xml" />

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$'], ['\\(','\\)']],
          processEscapes: true
        }
      });
      </script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <!-- <a href="/" class="site-avatar"><img src="https://avatars3.githubusercontent.com/u/7328228?s=460&v=4" /></a> -->

          <div class="site-info">
            <h4 class="site-name"><a href="/">Amlaan Bhoi</a></h4>
            <!-- <p class="site-description">Grad Student at UIC</p> -->
          </div>

          <!-- <nav>
            <a href="/">Blog</a>
            <a href="/about">About</a>
            <a href="https://abhoi.github.io">Home</a>
          </nav> -->
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h2>Introduction to Conditional Random Fields</h2>

  <div class="entry">
    <p align="justify">Conditional Random Fields (CRFs) are a class of statistical modeling method often to used to model structured data. CRFs are widely used in machine learning problems. Some specific applications include:</p>

<ul>
  <li><strong>Computer Vision</strong>: Object recognition, image segmentation</li>
  <li><strong>Natural Language Processing</strong>: POS tagging, Shallow parsing, Named entity recognition</li>
  <li><strong>Biological Sequences</strong>: Gene finding, Peptide critical functional region finding</li>
</ul>

<p>CRFs are used as an alternative to hidden Markov models (HMMs) as well. Conditional Random Fields were introduced in 2001 by Lafferty, John, Andrew McCallum, and Fernando CN Pereira [2].</p>

<p>A <strong>conditional random field</strong> or <strong>CRF</strong> is a <strong>Markov Random Field</strong> where all the clique potentials are conditioned on input features:</p>

<script type="math/tex; mode=display">p(\textbf{y}|\textbf{x, w}) = \frac{1}{Z(\textbf{x, w})}\prod_{c} \psi_{c}(\textbf{y}_{c}|\textbf{x, w})</script>

<p>A CRF is basically a <strong>structured ouput</strong> extension of <strong>logistic regression</strong>. We can assume a log-linear representation of the potentials:</p>

<script type="math/tex; mode=display">\psi_{c}(\textbf{y}_{c}|\textbf{x, w}) = exp(\textbf{w}_{c}^{T} \phi(\textbf{x, }\textbf{y}_{c}))</script>

<p align="justify">CRFs are more efficient than generative classifiers because they don't waste resources modeling things that they always observe. They only focus on the distribution of labels given data. This leads to the potentials of the model be data-dependent. If two nodes <i>x</i> and <i>y</i> are discontinuous, then we can "turn off" or set the transition potential to zero. [1]</p>

<p>We can also represent CRFs as:</p>

<script type="math/tex; mode=display">p(\textbf{y}|X) = \frac{1}{Z_X}\textrm{exp}\left (\sum_{s=1}^{m} \left \langle \textbf{w}_{y_{s}}, \textbf{x}_{s} \right \rangle + \sum_{s=1}^{m-1}T_{y_{s},y_{s+1}}\right)</script>

<script type="math/tex; mode=display">Z_X = \sum_{\mathbf{\hat{y}} \in \mathcal{Y}^{m}}^{ } \textrm{exp}\left (\sum_{s=1}^{m} \left \langle \textbf{w}_{\hat{y}_{s}}, \textbf{x}_{s} \right \rangle + \sum_{s=1}^{m-1}T_{\hat{y}_{s},\hat{y}_{s+1}}\right )</script>

<p align="justify">A key advantange of CRFs over Markov Random Fields (MRF) is that we don't "waste resources" modeling things that we always observe. Another advantage is that the potentials of the model are data-dependent. As an example, if we are classifying images, we can "turn off" label smoothing between two neighboring nodes $s$ and $t$. The only disadvantage of CRF over MRF is that they require labeled training data and are slower to train.</p>

<p align="justify">The most commonly used CRFs use a chain-structured graph to model correlation amongst neighboring labels. Traditionally, Hidden Markov Models (HMMs) are used for such tasks. These are joint density models of form:</p>

<script type="math/tex; mode=display">p(\mathbf{x}, \mathbf{y}|\mathbf{w}) = \prod_{t=1}^{T}p(y_{t}|y_{t-1}, \mathbf{w})p(\mathbf{x}_{t}|y_{t},\mathbf{w})</script>

<p align="justify">An HMM requires specifying a generative model which is difficult. Furthermore, each $\mathbf{x}_{t}$ is required to be local, since it is hard to define a generative model for the whole stream of observations $\mathbf{x}=\mathbf{x}_{1:T}$. An obvious way to make a descriminative version of an HMM is to "reverse the arrows" from $y_{t}$ to $\mathbf{x}_{t}$ to model a form as:</p>

<script type="math/tex; mode=display">p(\mathbf{x}, \mathbf{y}|\mathbf{w}) = \prod_{t}p(y_{t}|y_{t-1}, \mathbf{x},\mathbf{w})</script>

<p align="justify">This is called a <b>maximum entropy Markov model</b> or <b>MEMM</b>. An MEMM is simply a Markov chain whose state transition probabilities are conditioned on input features. A chain-structured CRF has the form:</p>

<script type="math/tex; mode=display">p(\mathbf{y}|\mathbf{x}, \mathbf{w}) = \frac{1}{Z(\mathbf{x}, \mathbf{w})}\psi (y_t|\mathbf{x}, \mathbf{w})\prod_{t=1}^{T-1}\psi(y_t, y_{t+1}|\mathbf{x}, \mathbf{w})</script>

<p align="justify">Chain-structured CRFs remove the <b>label bias</b> problem. The problem is that local features at time $t$ do not influence states prior to time $t$. In MEMMs, the label bias problem occurs because directed models are <b>locally normalized</b>, meaning each CPD sums to 1. By contrast, MRFs and CRFs are <b>globally normalized</b>, which means that local factors do not need to sum to 1, since partition function $Z$, which sums over all joint configurations, will ensure the model defines a valid distribution. The main disadvantage is that we do not get a valid probability distribution over $\mathbf{y}$ until we have seen the whole sentence. CRFs are also not as useful as DGMs for online or real-time inference. Also, $Z$ depends on all nodes which makes CRFs much slower to train.</p>

<p><strong>References</strong>:</p>

<ol>
  <li>Murphy, Kevin P. “Machine Learning: A Probabilistic Perspective. Adaptive Computation and Machine Learning.” (2012).</li>
  <li>Lafferty, John, Andrew McCallum, and Fernando CN Pereira. “Conditional random fields: Probabilistic models for segmenting and labeling sequence data.” (2001).</li>
</ol>

  </div>

  <div class="date">
    Written on September  9, 2018
  </div>

  
</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer"><i>"If we want machines to think, we need to teach them to see"</i> ~ Fei-Fei Li</footer>
      </div>
    </div>

    <!-- <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          













        </footer>
      </div>
    </div> -->

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-112406581-3', 'auto');
		ga('send', 'pageview', {
		  'page': '/crf1/',
		  'title': 'Introduction to Conditional Random Fields'
		});
	</script>
	<!-- End Google Analytics -->


  </body>
</html>
